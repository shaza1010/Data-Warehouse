# Data Warehouse ELT Project 

## ğŸ“Š Project Overview  
This repository implements a **three-layer data warehouse** architecture (Bronze â†’ Silver â†’ Gold) using T-SQL on SQL Server.  
Raw CRM and ERP CSV data are ingested into bronze tables, cleaned and normalized in silver, and finally exposed as analytical views (dimension + fact) in gold for analytics and reporting.

---

## âœ¨ Features  
- End-to-end pipeline from CSV â†’ analytics-ready views
- Ingestion of CRM and ERP data from CSV files  
- Three-layer architecture:  
  - **Bronze:** Raw staging of source files  
  - **Silver:** Data cleaning, normalization, deduplication  
  - **Gold:** Final dimensional models (facts & dimensions)  
- Surrogate key generation for dimension tables  
- Ready for BI tools (Power BI, Tableau, etc.)

---

## ğŸ›  Tools & Technologies  
- **SQL Server** for schema, transformations, and views  
- **T-SQL** for data cleansing and modeling  
- **CSV files** as input sources (CRM + ERP)  

---
 
## ğŸ“‚ Repository Structure  
```
dataset/
â”‚   â”œâ”€â”€ source_crm/
â”‚   â”‚   â”œâ”€â”€ cust_info.csv
â”‚   â”‚   â”œâ”€â”€ prd_info.csv
â”‚   â”‚   â””â”€â”€ sales_details.csv
â”‚   â””â”€â”€ source_erp/
â”‚       â”œâ”€â”€ loc_a101.csv
â”‚       â”œâ”€â”€ cust_az12.csv
â”‚       â””â”€â”€ px_cat_g1v2.csv
scripts/
â”‚   â”œâ”€â”€ Bronze_layer.sql
â”‚   â”œâ”€â”€ Silver_layer.sql
â”‚   â””â”€â”€ Gold_layer.sql
README.md
```
---

- `dataset/source_crm` â€” Input CSVs from CRM  
- `dataset/source_erp` â€” Input CSVs from ERP  
- `scripts/` â€” SQL scripts for each layer  
- `README.md` â€” This documentation  

---

## ğŸ§± Layers & Transformation Logic

### Bronze Layer (`Bronze_layer.sql`)  
- Creates the `bronze` schema and raw staging tables  
- Defines a stored procedure `bronze.load_bronze` that truncates and bulk-inserts the CSV data into staging tables  
- Minimal transformations or cleansing â€” preserves raw values and structure  

### Silver Layer (`Silver_layer.sql`)  
- Creates the `silver` schema and cleaned/normalized tables  
- For each domain (customers, products, sales, ERP tables), apply:  
  - Data trimming/whitespace cleanup  
  - Normalization (e.g. marital status codes â†’ â€œSingleâ€ / â€œMarriedâ€, gender codes â†’ â€œMaleâ€ / â€œFemaleâ€)  
  - Conversion of types (e.g. integer dates â†’ `DATE`)  
  - Null handling and default substitutions  
  - Deduplication (via `ROW_NUMBER()` partitioning)  
  - Inserts into silver tables with a metadata column `dwh_create_date` to capture load timestamp  

### Gold Layer (`Gold_layer.sql`)  
- Creates the `gold` schema and defines views for analytics:  
  - `gold.dim_customers` â€” customer dimension combining CRM + ERP enrichments  
  - `gold.dim_products` â€” product dimension enriched with category metadata  
  - `gold.fact_sales` â€” fact table joining sales with dimensions  
- Implements surrogate key generation (with `ROW_NUMBER()`) and filters to exclude historical or invalid data  

---

## ğŸ“‹ Summary Table  

| Layer     | Purpose / Role                               | Key Logic & Transformations                              |
|-----------|----------------------------------------------|-----------------------------------------------------------|
| **Bronze** | Raw ingestion/staging of source CSVs       | Bulk load via `BULK INSERT`, preserve original values     |
| **Silver** | Clean / normalize / dedupe / validate        | Trim, code normalization, type conversion, deduplication  |
| **Gold**   | Analytics models / dimension & fact exposure | Create views, surrogate keys, enrich and join data       |

---

## âš¡ Getting Started / Execution Order

1. **Prepare database environment**  
   - Create a database (e.g. `DataWarehouse`)  
   - Ensure that the server has access to the CSV file paths used in your `BULK INSERT` statements in `Bronze_layer.sql`.

2. **Run SQL scripts in order**  
   - `Bronze_layer.sql` â†’ create bronze schema/tables + load raw CSVs  
   - `Silver_layer.sql` â†’ transform, clean, and insert into silver schema  
   - `Gold_layer.sql` â†’ build the analytical views  

3. **Verify results**  
   - Query views: `SELECT * FROM gold.dim_customers;`, `SELECT * FROM gold.fact_sales;`, etc.  
   - Optionally compare row counts between layers or run data quality checks.

---

## ğŸ”® Future Enhancements  
- Integrate with **BI/dashboard tools** (Power BI, Tableau)  
- Containerize or automate environment setup (e.g. Docker, CI/CD pipelines)  

---

## ğŸ‘© Author & Credits  
- **Author:**  *[Shaza Osman](https://www.linkedin.com/in/shaza-ag-osman/)*  
- **Date:** *Sep. 2025* 
